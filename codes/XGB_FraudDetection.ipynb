{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and Gradient Boosted Trees used for Fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('FraudTreeMethods').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 439\n",
      "+------+---+------+---+-------+-------------------+---------------+-------------+\n",
      "|    ip|app|device| os|channel|         click_time|attributed_time|is_attributed|\n",
      "+------+---+------+---+-------+-------------------+---------------+-------------+\n",
      "| 87540| 12|     1| 13|    497|2017-11-07 09:30:38|           null|            0|\n",
      "|105560| 25|     1| 17|    259|2017-11-07 13:40:27|           null|            0|\n",
      "|101424| 12|     1| 19|    212|2017-11-07 18:05:24|           null|            0|\n",
      "| 94584| 13|     1| 13|    477|2017-11-07 04:58:08|           null|            0|\n",
      "| 68413| 12|     1|  1|    178|2017-11-09 09:00:09|           null|            0|\n",
      "| 93663|  3|     1| 17|    115|2017-11-09 01:22:13|           null|            0|\n",
      "| 17059|  1|     1| 17|    135|2017-11-09 01:17:58|           null|            0|\n",
      "|121505|  9|     1| 25|    442|2017-11-07 10:01:53|           null|            0|\n",
      "|192967|  2|     2| 22|    364|2017-11-08 09:35:17|           null|            0|\n",
      "|143636|  3|     1| 19|    135|2017-11-08 12:35:26|           null|            0|\n",
      "| 73839|  3|     1| 22|    489|2017-11-08 08:14:37|           null|            0|\n",
      "| 34812|  3|     1| 13|    489|2017-11-07 05:03:14|           null|            0|\n",
      "|114809|  3|     1| 22|    205|2017-11-09 10:24:23|           null|            0|\n",
      "|114220|  6|     1| 20|    125|2017-11-08 14:46:16|           null|            0|\n",
      "| 36150|  2|     1| 13|    205|2017-11-07 00:54:09|           null|            0|\n",
      "| 72116| 25|     2| 19|    259|2017-11-08 23:17:45|           null|            0|\n",
      "|  5314|  2|     1|  2|    477|2017-11-09 07:33:41|           null|            0|\n",
      "|106598|  3|     1| 20|    280|2017-11-09 03:44:35|           null|            0|\n",
      "| 72065| 20|     2| 90|    259|2017-11-06 23:14:08|           null|            0|\n",
      "| 37301| 14|     1| 13|    349|2017-11-06 20:07:00|           null|            0|\n",
      "+------+---+------+---+-------+-------------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+-------------+--------------------+\n",
      "|prediction|is_attributed|            features|\n",
      "+----------+-------------+--------------------+\n",
      "|       0.0|            0|[9.0,9.0,1.0,13.0...|\n",
      "|       0.0|            0|[10.0,11.0,1.0,22...|\n",
      "|       0.0|            0|[20.0,2.0,1.0,16....|\n",
      "|       0.0|            0|[20.0,12.0,1.0,13...|\n",
      "|       0.0|            0|[25.0,3.0,1.0,23....|\n",
      "+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "#data = sqlContext.sql(\"SELECT * FROM fraud_train_sample_csv\")\n",
    "data = spark.read.csv('train_sample.csv', inferSchema=True, header=True)\n",
    "\n",
    "# over sampling\n",
    "major_df = data.filter(col(\"is_attributed\") == 0)\n",
    "minor_df = data.filter(col(\"is_attributed\") == 1)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))\n",
    "a = range(ratio)\n",
    "\n",
    "# duplicate the minority rows\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')\n",
    "\n",
    "# combine both oversampled minority rows and previous majority rows combined_df = major_df.unionAll(oversampled_df)\n",
    "combined_df = major_df.unionAll(oversampled_df)\n",
    "combined_df.show()\n",
    "data = combined_df\n",
    "data = data.drop('click_time','attributed_time')\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "assembler = VectorAssembler(inputCols=['ip', 'app', 'device', 'os', 'channel'],outputCol=\"features\")\n",
    "trainingData = assembler.transform(trainingData)\n",
    "testData = assembler.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+\n",
      "|prediction|is_attributed|            features|\n",
      "+----------+-------------+--------------------+\n",
      "|       0.0|            0|[9.0,9.0,1.0,13.0...|\n",
      "|       0.0|            0|[10.0,11.0,1.0,22...|\n",
      "|       0.0|            0|[20.0,2.0,1.0,16....|\n",
      "|       0.0|            0|[20.0,12.0,1.0,13...|\n",
      "|       0.0|            0|[25.0,3.0,1.0,23....|\n",
      "+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"is_attributed\", featuresCol=\"features\", maxIter=20, maxDepth=4)\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = gbt.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"is_attributed\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0482078\n",
      "Test accuracy = 0.951792\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"is_attributed\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print(\"Test accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|30647|\n",
      "|       1.0|29281|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to test, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|click_id|prediction|\n",
      "+--------+----------+\n",
      "|       0|       1.0|\n",
      "|       1|       0.0|\n",
      "|       2|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+-------------+\n",
      "|click_id|is_attributed|\n",
      "+--------+-------------+\n",
      "|       0|          1.0|\n",
      "|       1|          0.0|\n",
      "|       2|          0.0|\n",
      "+--------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------------+--------+\n",
      "|is_attributed|   count|\n",
      "+-------------+--------+\n",
      "|          0.0|17946533|\n",
      "|          1.0|  843936|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = spark.read.csv('test.csv', inferSchema=True, header=True)\n",
    "#test.show(5)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['ip', 'app', 'device', 'os', 'channel'],outputCol=\"features\")\n",
    "test = assembler.transform(test)\n",
    "#test.show(3)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "#predictions.show(2)\n",
    "\n",
    "data_to_submit = predictions.select(['click_id','prediction'])\n",
    "data_to_submit.show(3)\n",
    "\n",
    "data_to_submit = data_to_submit.withColumnRenamed('prediction','is_attributed')\n",
    "data_to_submit.show(3)\n",
    "\n",
    "data_to_submit.groupBy('is_attributed').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "FraudDetection_RF_XGB",
  "notebookId": 404476875724424
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
